{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applied Statistics #\n",
    "\n",
    "## Tasks ##\n",
    "\n",
    "This notebook contains my work for four tasks which form part of the assessment for the Applied Statistics module of the Higher Diploma in Data Analytics from ATU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Permutations and Combinations ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This task involves a slight modification of Ronald A. Fisher's \"Lady Tasting Tea\" experiment from 1935. This experiment involves making eight cups of tea, four of which have the tea put in first followed by the milk and the other four with the milk put in first followed by the tea; the lady referred to in the name of the experiment then tastes each cup of tea and tries to determine which cups had the milk put in first. Instead of using eight cups, we will analyse the experiment including twelve cups of tea."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The task as outlined by the lecturer is as follows:\n",
    "\n",
    "*Suppose we alter the Lady Tasting Tea experiment to involve twelve cups of tea. Six have the milk in first and the other six having tea in first. A person claims they have the special power of being able to tell whether the tea or the milk went into a cup first upon tasting it. You agree to accept their claim if they can tell which of the six cups in your experiment had the milk in first.*\n",
    "\n",
    "*1. Calculate, using Python, the probability that they select the correct six cups. Here you should assume that they have no special powers in figuring it out, that they are just guessing. Remember to show and justify your workings in code and MarkDown cells.*\n",
    "\n",
    "*2. Suppose, now, you are willing to accept one error. Once they select the six cups they think had the milk in first, you will give them the benefit of the doubt should they have selected at least five of the correct cups. Calculate the probability, assuming they have no special powers, that the person makes at most one error.*\n",
    "\n",
    "*3. Would you accept two errors? Explain.*\n",
    "\n",
    "<img src=\"https://www.teamuse.com/img/articles/000804_1.jpg\" width=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To complete this task, I will first install the same libraries that the lecturer installed before he analysed the original version of the experiment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mathematical functions from the standard library.\n",
    "# https://docs.python.org/3/library/math.html\n",
    "import math\n",
    "\n",
    "# Permutations and combinations.\n",
    "# https://docs.python.org/3/library/itertools.html\n",
    "import itertools\n",
    "\n",
    "# Random selections.\n",
    "# https://docs.python.org/3/library/random.html\n",
    "import random\n",
    "\n",
    "# Numerical structures and operations.\n",
    "# https://numpy.org/doc/stable/reference/index.html#reference\n",
    "import numpy as np\n",
    "\n",
    "# For data manipulation and analysis\n",
    "import pandas as pd\n",
    "\n",
    "# Plotting.\n",
    "# https://matplotlib.org/stable/contents.html\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# for mathemetical and statistic functions\n",
    "import scipy.stats "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To answer the first question, we need to find the probability of correctly guessing 6 cups of tea out of 12 cups. The order that we select the 6 cups does not matter, so we are looking for the correct combination of 6 cups from the 12 cups. \n",
    "\n",
    "*If* we cared about the order the cups were selected, we would be seeking a **permutation** of the 12 listed a specific order, including the 6 cups with the milk put in first. \n",
    "\n",
    "Instead, to calculate the **combination** of 6 cups from 12, we can use the `math.comb()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Firstly we calculate the number of ways of selecting any 6 cups from the 12 cups\n",
    "all_combinations = math.comb(12,6)\n",
    "\n",
    "# The probability of selecting the one correct combination of 6 cups correctly from the 12 cups\n",
    "prob_6_correct = 1 / all_combinations\n",
    "\n",
    "# Printing the probability result out to four decimal places\n",
    "print(f\"The probability of correctly selecting all 6 'milk-first' cups is {round(prob_6_correct, 4)}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the next question, we need to calculate the probability that the person makes *at most* one error. This means that they either select 5 of the 6 cups correctly, or else they select all 6 correctly. To find the probability of this happening if the person has no special power to guess, we find the probability of selecting 5 cups correctly and add it to the probability of selecting all 6 correctly, which was calculated in the answer to the first question above.\n",
    "\n",
    "The probability of correctly selecting 5 out of the 6 'milk-first' cups requires us to work out how many combinations of 5 'milk-first' cups can be selected from the 6 'milk-first' cups and then multiplying this number of scenarios by the number of ways it is then possible to select 1 of the remaining 'tea-first' cups; this answer to the latter part is simply 6, as there are only 6 'tea-first' cups to choose from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the number of combinations of 5 milk-first cups out of the 6 available, and multiplying it by the number of ways to \n",
    "# select 1 tea-first cup from the remaining 6 such cups\n",
    "ways_5_correct = math.comb(6,5) * math.comb (6,1)\n",
    "\n",
    "# dividing the above figure by the number of ways of selecting any 6 cups from the 12 cups\n",
    "prob_5_correct = ways_5_correct / all_combinations\n",
    "\n",
    "# finding the probability of selecting at most 1 wrong ie. at least 5 out of 6 correct\n",
    "prob_5_or_6_correct = prob_5_correct + prob_6_correct\n",
    "\n",
    "# Printing the probability result out to four decimal places\n",
    "print(f\"The probability of correctly selecting at least 5 of the 'milk-first' cups is {round(prob_5_or_6_correct, 4)}.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The third part of this task asks us to consider whether we would accept two errors. Another way of phrasing this might be, would we consider selecting 4 out of the 6 'milk-first' cups to be indicative of a special ability to determine whether a cup of tea had the milk or tea poured into it first, or would we consider the probability too high that somebody who doesn't have such a special ability could correctly select 4 'milk-first' cups by chance?\n",
    "\n",
    "To calculate the probability of selecting 4 or more of the 'milk-first' cups correctly, we can do a similar calculation to the one we did to calculate the probability of selecting 5 or more correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The number of ways to select 4 out of the 6 'milk-first' cups multiplied by the number of ways to select 2 out of the 6 'tea-first' cups.\n",
    "ways_4_correct = math.comb(6,4) * math.comb (6,2)\n",
    "\n",
    "# dividing the above figure by the number of ways of selecting any 6 cups from the 12 cups\n",
    "prob_4_correct = ways_4_correct / all_combinations\n",
    "\n",
    "# finding the probability of selecting at most 2 wrong ie. at least 4 out of 6 correct, using the result from the last question\n",
    "prob_4_or_5_or_6_correct = prob_4_correct + prob_5_or_6_correct\n",
    "\n",
    "# Printing the result out to four decimal places\n",
    "print(f\"The probability of correctly selecting at least 4 of the 'milk-first' cups is {round(prob_4_or_5_or_6_correct, 4)}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To visualise how relatively likely selecting 4 'milk-first' cups correctly is compared with other possible outcomes, I will create a bar chart of the probability of each of the 7 possible outcomes (ie. selecting from 0 to 6 'milk-first' cups). To do this, I will first need to calculate each probability using the same combinations calculation I used for the probability of selecting 4, 5 and 6 'milk-first' cups correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "ways_0_correct = math.comb(6,0) * math.comb(6,6)\n",
    "prob_0_correct = ways_0_correct / all_combinations\n",
    "\n",
    "ways_1_correct = math.comb(6,1) * math.comb(6,5)\n",
    "prob_1_correct = ways_1_correct / all_combinations\n",
    "\n",
    "ways_2_correct = math.comb(6,2) * math.comb(6,4)\n",
    "prob_2_correct = ways_2_correct / all_combinations\n",
    "\n",
    "ways_3_correct = math.comb(6,3) * math.comb(6,3)\n",
    "prob_3_correct = ways_3_correct / all_combinations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will now plot all seven probability figures on a bar chart:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of outcomes to include in the bar chart across the x-axis, and the probabilities of each outcome across the y-axis\n",
    "outcomes = [\"0 Correct\", \"1 Correct\", \"2 Correct\", \"3 Correct\", \"4 Correct\", \"5 Correct\", \"6 Correct\"]\n",
    "probabilities = [prob_0_correct, prob_1_correct, prob_2_correct, prob_3_correct, prob_4_correct, prob_5_correct, prob_6_correct]\n",
    "\n",
    "# To colour the bars for 4 or more cups differently to the bars for 3 or fewer cups, we can use an if-else statement\n",
    "colours = [\"gold\" if outcome in [\"0 Correct\", \"1 Correct\", \"2 Correct\", \"3 Correct\"] else \"brown\" for outcome in outcomes]\n",
    "\n",
    "# plotting the bar chart \n",
    "# https://www.geeksforgeeks.org/bar-plot-in-matplotlib/\n",
    "plt.figure(figsize=(8, 5))\n",
    "\n",
    "# Passing in the numerical data for each outcome, colouring the bars, and giving the bars darkened sides to improve appearance\n",
    "# https://python-graph-gallery.com/3-control-color-of-barplots/\n",
    "plt.bar(outcomes, probabilities, color=colours, edgecolor='black')\n",
    "plt.xlabel(\"Number of 'milk-first' cups selected\")\n",
    "plt.ylabel(\"Probability\")\n",
    "plt.title(\"Probability of selecting zero to six 'milk-first' cups correctly\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From looking at this bar chart, I am even more convinced that allowing a person the chance to make two errors is too generous an allowance to give, as such an outcome if not unlikely by any means."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: numpy's Normal Distribution ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The lecturer's instruction for this task is as follows:\n",
    "\n",
    "*1. In this task you will assess whether numpy.random.normal() properly generates normal values. To begin, generate a sample of one hundred thousand values using the function with mean 10.0 and standard deviation 3.0.*\n",
    "\n",
    "*Use the scipy.stats.shapiro() function to test whether your sample came from a normal distribution. Explain the results and output.*\n",
    "\n",
    "*2. Plot a histogram of your values and plot the corresponding normal distribution probability density function on top of it.*\n",
    "\n",
    "Before beginning this task, I will import additional libraries used by the lecturer when demonstrating the normal distribution with his code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistics.\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Statistical models.\n",
    "import statsmodels as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To generate a sample of 100,000 vaues using the *nump.random.normal()* function, with mean 10.0 and deviation 3.0, we pass in the arguments as below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reference: https://numpy.org/doc/2.0/reference/random/generated/numpy.random.normal.html\n",
    "data = np.random.normal(loc=10.0, scale=3.0, size=100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Shapiro-Wilk test tests the null hypothesis that the data was drawn from a Normal distribution. If the result obtained is extreme enough, we take it as evidence that the null hypothesis is false and that the data is *not* normally distributed. The inverse is not true ie. a non-extreme result cannot be taken as evidence that the data *is* normally distributed. The value of this statistic tends to be high (close to 1) for samples drawn from a normal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the Shapiro Wilk test.\n",
    "stats.shapiro(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will now plot a histogram of the data with the Normal Distribution probability density function plotted on top of it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the norm.pdf function to allow us to create the the Normal distribution probability density function\n",
    "from scipy.stats import norm\n",
    "\n",
    "# Creating a blank plot where we will plot both the histogram of our 100000 values and the Normal distribution pdf\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Passing in the random sample data, colouring the bars, and giving the bars darkened sides to improve appearance\n",
    "plt.hist(data, bins=50, color='wheat', density = True, edgecolor='black')\n",
    "\n",
    "# Generating 1001 evenly-separated numbers between the minimum and maximum of the data generated above:\n",
    "x_axis_pdf = np.linspace(min(data), max(data), 1001)\n",
    "\n",
    "# Here we use the norm() function from scipy.stats  to create a Normal Distribution probability density function (pdf):\n",
    "# We colour it red, with linewidth = 2.\n",
    "plt.plot(x_axis_pdf, norm.pdf(x_axis_pdf, 10, 3), '-r', linewidth = 2)\n",
    "\n",
    "# Adding the title and labels for the axes:\n",
    "plt.title(\"Random sample of 100000 values from numpy.random.normal function\", fontsize = 14)\n",
    "plt.xlabel(\"Value\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3: t-Test Calculation ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Task 3, the lecturer has asked us to *consider a dataset containing resting heart rates for patients before and after embarking on a two-week exercise program.*\n",
    "\n",
    "We are asked to *calculate the t-statistic based on this data set, using Python. Compare it to the value given by scipy.stats. Explain your work and list any sources used.*\n",
    "\n",
    "The below table of data was provided, which I will convert into a pandas dataframe to complete the task:\n",
    "\n",
    "![resting heart rate data](img/task-3-data.jpg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas to allow us to create a dataframe\n",
    "import pandas as pd\n",
    "\n",
    "# storing the data in arrays\n",
    "patient_ids = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "heart_rate_before = [63, 68, 70, 64, 74, 67, 70, 57, 66, 65]\n",
    "heart_rate_after = [64, 64, 68, 64, 73, 70, 72, 54, 61, 63]\n",
    "\n",
    "# creating the dataframe\n",
    "heart_rate_data = {\n",
    "    \"Patient ID\": patient_ids,\n",
    "    \"Before\": heart_rate_before,\n",
    "    \"After\": heart_rate_after\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(heart_rate_data)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this dataset consists of before and after data for each patient, the before and after data points can be considered paired data for each patient. Therefore, the t-test we will perform is the paired difference t-test.\n",
    "\n",
    "Before performing this t-test, however, we will plot the before and after data on a histogram to get a sense of how the data is distributed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Histogram for heart_rate_before. By using the alpha paramter we can make the plot slightly transparent to allow\n",
    "# us to overlap with that for heart_rate_after\n",
    "plt.hist(heart_rate_before, bins=5, alpha= 0.7, label='Heart Rate Before', color='yellow', edgecolor='black')\n",
    "\n",
    "# Histogram for heart_rate_after:\n",
    "plt.hist(heart_rate_after, bins=5, alpha=0.7, label='Heart Rate After', color='pink', edgecolor='black')\n",
    "\n",
    "# Adding titles and labels\n",
    "plt.title('Heart Rate Distribution Before and After', fontsize=14)\n",
    "plt.xlabel('Heart Rate', fontsize=10)\n",
    "plt.ylabel('Frequency', fontsize=10)\n",
    "plt.legend(fontsize=10)\n",
    "\n",
    "# Show plot\n",
    "plt.grid(axis='y', alpha=0.75)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see that the \"after\" data has a distribution shifted to the left compared with the \"before\" data.\n",
    "\n",
    "We will now use the pre-built function `ttest_rel` from scipy stats to calculate this statistic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_rel\n",
    "\n",
    "# Passing in the data in the Before and After columns of the pandas dataframe created above\n",
    "t_stat, p_value = ttest_rel(df[\"Before\"], df[\"After\"])\n",
    "\n",
    "print(f\"The T-statistic is {t_stat}\")\n",
    "print(f\"The p_value is {p_value}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will calculate this statistic ourselves. \n",
    "\n",
    "In this test, the null hypothesis is that the mean difference between the blood pressure of patients before and after treatment is equal to zero. \n",
    "\n",
    "The alternative hypothesis is that the mean difference between the blood pressure of patients before and after treatment is **not** equal to zero. \n",
    "\n",
    "The T-statistic is calculated as T = Mean difference/ (Standard error of mean difference), with n-1 degrees of freedom.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Firstly I will calculate an array of differences for the before and after columns by subtracting an array of the after values\n",
    "# from an array of the before values\n",
    "differences = np.array(heart_rate_before) - np.array(heart_rate_after)\n",
    "\n",
    "print(differences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next I will find the mean of these differences across the number of patients studied. For this task, we are examining the data of ten patients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here the len function returns the number of items in the array 'patient_ids'\n",
    "n = len(patient_ids)\n",
    "\n",
    "# Here the sum function sums up the contents of the 'differences' array calculated above\n",
    "sum_diff = sum(differences)\n",
    "\n",
    "# This divides the second figure by the first\n",
    "mean_diff = sum_diff/n \n",
    "\n",
    "print(mean_diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will now calculate the standard error, which is equal to the (standard deviation/Sqrt n). \n",
    "\n",
    "Firstly, I will calculate the standard deviation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first step is to calculate the extent to which each of the ten figures for the difference between before and after measurement\n",
    "# deviates from the mean of all the differences between before and after measurements\n",
    "# I will store these differences in an array\n",
    "deviations = np.array(differences) - np.array(mean_diff)\n",
    "\n",
    "squared_deviations = deviations ** 2\n",
    "\n",
    "sum_squared_deviations = np.sum(squared_deviations)\n",
    "\n",
    "variance = sum_squared_deviations/ (n - 1)\n",
    "\n",
    "s = np.sqrt(variance)\n",
    "\n",
    "print(s)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate the standard error, we divide the standard deviation by the square root of n:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_error = s/np.sqrt(n)\n",
    "\n",
    "print(standard_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the T-statisic can be calculated as Mean difference/ standard error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# T-statistic\n",
    "t_stat = mean_diff/ standard_error\n",
    "\n",
    "print(f\"The manually calculated T-statistic is {t_stat}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This figure for the T-statistic (approx 1.3372) is the same as that calculated using the built in function `ttest_rel` from scipy stats."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4: ANOVA ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The lecturer's instructions for this Task are as follows: \n",
    "\n",
    "*In this test we will estimate the probability of committing a type II error in specific circumstances. To begin, create a variable called no_type_ii and set it to 0.*\n",
    "\n",
    "*Now use a loop to perform the following test 10,000 times.*\n",
    "\n",
    "*Use numpy.random.normal to generate three samples with 100 values each. Give each a standard deviation of 0.1. Give the first sample a mean of 4.9, the second a mean of 5.0, and the third a mean of 5.1.*\n",
    "\n",
    "*Perform one-way anova on the three samples and add 1 to no_type_ii whenever a type II error occurs.*\n",
    "\n",
    "*Summarize and explain your results.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are asked to increment the value of 'no_type_ii' by 1 each time a type II error occurs. A type II error means we fail to reject the null hypothesis even though it is false. In the context of this experiment, the null hypothesis is that the mean of each sample is equal ie. **μ1 = μ2 = μ3** where μ1 is the mean of sample 1, μ2 is the mean of sample 2 and μ3 is the mean of sample 3. If any of these three means differ from one another, the null hypothesis is false.\n",
    "\n",
    "Since we generated the samples with different means, we would expect the means to be different from each other and to reject the null hypothesis. \n",
    "\n",
    "To investigate whether the null hypothesis might be false, we can use scipt.stats f_oneway function to calculate the F statistic for a one-way ANOVA, along with the associated p_value. The F-statistic compares to level of variation between groups with the level of variation within groups. The p-value describes the probability of observing a result as extreme as the result which was found, if the null hypothesis was true ie. μ1 = μ2 = μ3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we create a variable called 'no_type_ii'\n",
    "no_type_ii = 0\n",
    "\n",
    "# Next we create three samples, each with a standard deviation of 0.1 but with slightly differing means.\n",
    "# Here loc = mean, and scale = standard deviation\n",
    "# We will generate three samples of size 100, 10000 times:\n",
    "for i in range(10000):\n",
    "\n",
    "    # Here we are generating the samples\n",
    "    sample1 = np.random.normal(loc=4.9, scale=0.1, size=100)  \n",
    "    sample2 = np.random.normal(loc=5.0, scale=0.1, size=100)\n",
    "    sample3 = np.random.normal(loc=5.1, scale=0.1, size=100)\n",
    "\n",
    "    # Here we are constructing a data frame to allow us to use the f_oneway function from scipy stats to find the F-statistic and p-value\n",
    "    # for each of the 10000 iterations of this experiment\n",
    "    df = pd.DataFrame({'Sample1': sample1, 'Sample2': sample2, 'Sample3': sample3})\n",
    "\n",
    "    # Here we perform a one-way ANOVA between the three different samples within the data frame just created\n",
    "    f_statistic, p_value = stats.f_oneway(df['Sample1'], df['Sample2'], df['Sample3'])\n",
    "\n",
    "    if p_value > 0.05:\n",
    "        no_type_ii += 1\n",
    "\n",
    "print('The value of no_type_ii is given below:')\n",
    "print(no_type_ii)\n",
    "print()\n",
    "print(f'An example of an F-statistic from these 10,000 iterations is {f_statistic} and the accompanying p-value is {p_value}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find that the F-statistics are very high, and across 10,000 iterations of generating samples of 100 values with the prescribed means and standard deviations, we find that at no point is the p-value greater than 0.05; the value of no_type_ii does not become incremented at all over the course of 10000 iterations.\n",
    "\n",
    "In fact, a quick look at the p-values shows that, under the assumption that the null hypothesis of equal means is true, the likelihood of outcomes as extreme as those which did happen is bordering on impossible. To put in context what even a probability of 1 x e^-30 means: the universe is around 4.37 x 10^17 seconds old (universe age = 13.85 billion years of 365.2425 days), so if this experiment was performed 1 trillion (10^12) times per second since the universe was formed, there is a good chance you still wouldn't get means so different as those generated here, if the means are inherently the same for each sample.\n",
    "\n",
    "We can perform a post-hoc test on the samples generated. We will use Tukey's honestly significant difference test (HSD):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = stats.tukey_hsd(df['Sample1'], df['Sample2'], df['Sample3'])\n",
    "\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References ###\n",
    "\n",
    "#### Task 1 ####\n",
    "\n",
    "\n",
    "\n",
    "#### Task 2 ####\n",
    "\n",
    "#### Task 3 ####\n",
    "\n",
    "#### Task 4 ####\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
